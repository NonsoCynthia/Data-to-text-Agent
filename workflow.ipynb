{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinonso/anaconda3/envs/lang2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Literal, Optional, Text, Union, Dict, Any\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph_mermaid import MermaidDrawMethod\n",
    "from agents.agents_modules.workflow import build_agent_workflow, workers_dict\n",
    "from agents.dataloader import load_dataset_by_name, extract_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: totto\n",
      "Input: <page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>\n",
      "Target: In 2009, Liza Lapira played Sophie Trinh in the film Fast & Furious and Alva in the 2010 film Repo Men.\n",
      "Ground Truth: ['In 2009, Liza Lapira played Sophie Trinh in the film Fast & Furious and Alva in the 2010 film Repo Men.']\n"
     ]
    }
   ],
   "source": [
    "name = \"totto\"  # Change this to the dataset you want to load\n",
    "n = 249 # Sample id\n",
    "\n",
    "data = load_dataset_by_name(name)\n",
    "sample = extract_example(name, data[\"train\"][n])\n",
    "data = sample['input']\n",
    "ground_truth = sample['references']\n",
    "target = sample['target']\n",
    "\n",
    "query = f\"\"\"You are an agent designed to generate text from data for a data-to-text natural language generation. You can be provided data in the form of xml, table, meaning representations, graphs etc. \n",
    "Your task is to generate the appropriate text given the data information without omitting any field or adding extra information in essence called hallucination.\n",
    "Here is the data generate text using table data:\n",
    "{data}\"\"\"\n",
    "\n",
    "initial_state = {\n",
    "    \"input\": query,\n",
    "    \"plan\": [],\n",
    "    \"result_steps\": [],\n",
    "    \"response\": \"\",\n",
    "    \"chat_history\": [],\n",
    "    \"next\": \"\",\n",
    "    \"next_input\": \"\",\n",
    "    \"agent_outcome\": \"\",\n",
    "    \"current_step\": 0,\n",
    "    \"team_iterations\": 0,\n",
    "    \"recursion_limit\": 30,\n",
    "}\n",
    "\n",
    "print(f\"Input: {data}\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Ground Truth: {ground_truth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"openai\" #ollama, openai, hf, aixplain\n",
    "process_flow = build_agent_workflow(add_plan=True, workers_dict=workers_dict, provider=provider)\n",
    "# display(Image(process_flow.get_graph(xray=True).draw_mermaid_png(draw_method=MermaidDrawMethod.PYPPETEER)))\n",
    "# display(Image(process_flow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORCHESTRATOR OUTPUT:\n",
      "Thought: The user has provided structured data about Liza Lapira's filmography in a tabular format. This includes the titles of films she appeared in, the year of release, and the roles she played. I will start with the 'content ordering' worker to gather and arrange the relevant fields in the correct order for our final output.\n",
      "\n",
      "Worker: content ordering\n",
      "Worker Input: \n",
      "- Original input data: \n",
      "  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\n",
      "- Current context: Focus on arranging the filmography data extracted from the table, noting the years, titles, and roles. \n",
      "\n",
      "Ordered Fields:\n",
      "1. Year: 2009, Title: Fast & Furious, Role: Sophie Trinh\n",
      "2. Year: 2010, Title: Repo Men, Role: Alva\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to reorder the input data based on the extracted filmography information, maintaining the XML structure while ensuring coherence in the ordering of the fields.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "WORKER: {'input': '- Original input data: \\n  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\\n- Current context: Focus on arranging the filmography data extracted from the table, noting the years, titles, and roles. \\n\\nOrdered Fields:\\n1. Year: 2009, Title: Fast & Furious, Role: Sophie Trinh\\n2. Year: 2010, Title: Repo Men, Role: Alva', 'output': '<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>'}\n",
      "INSPECTOR: CORRECT\n",
      "ORCHESTRATOR OUTPUT:\n",
      "Thought: The content ordering step has been successfully executed, with the filmography data arranged according to the years, titles, and roles in a clear format. The ordered fields indicate the structured information required for the next step, focusing on transforming this ordered structure into coherent paragraphs or sentences.\n",
      "\n",
      "Worker: text structuring\n",
      "Worker Input: \n",
      "'- Original input data: \n",
      "  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\n",
      "- Current context: The ordered fields are: \n",
      "  1. Year: 2009, Title: Fast & Furious, Role: Sophie Trinh\n",
      "  2. Year: 2010, Title: Repo Men, Role: Alva\n",
      "\n",
      "Structured Content:\n",
      "Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"'\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film 'Fast & Furious.' The following year, in 2010, she played the role of Alva in the movie 'Repo Men.'\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "WORKER: {'input': '\\'- Original input data: \\n  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\\n- Current context: The ordered fields are: \\n  1. Year: 2009, Title: Fast & Furious, Role: Sophie Trinh\\n  2. Year: 2010, Title: Repo Men, Role: Alva\\n\\nStructured Content:\\nLiza Lapira\\'s filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"\\'', 'output': \"Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film 'Fast & Furious.' The following year, in 2010, she played the role of Alva in the movie 'Repo Men.'\"}\n",
      "INSPECTOR: CORRECT\n",
      "ORCHESTRATOR OUTPUT:\n",
      "Thought: The content has been successfully ordered and structured. Now, I need to generate fluent natural language text from the structured content about Liza Lapira's filmography. \n",
      "\n",
      "Worker: surface realization\n",
      "Worker Input: '- Original input data: \n",
      "  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\n",
      "- Current context: Structured Content: \n",
      "  Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"\n",
      "\n",
      "Output Text: Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"'\n",
      "  \n",
      "FINISH\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \\\"Fast & Furious.\\\" The following year, in 2010, she played the role of Alva in the movie \\\"Repo Men.\\\"\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "WORKER: {'input': '\\'- Original input data: \\n  `<page_title> Liza Lapira </page_title> <section_title> Filmography </section_title> <table> <cell> 2009 <col_header> Year </col_header> </cell> <cell> Fast & Furious <col_header> Title </col_header> </cell> <cell> Sophie Trinh <col_header> Role </col_header> </cell> <cell> 2010 <col_header> Year </col_header> </cell> <cell> Repo Men <col_header> Title </col_header> </cell> <cell> Alva <col_header> Role </col_header> </cell> </table>`\\n- Current context: Structured Content: \\n  Liza Lapira\\'s filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"\\n\\nOutput Text: Liza Lapira\\'s filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"\\'\\n  \\nFINISH', 'output': 'Liza Lapira\\'s filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"'}\n",
      "INSPECTOR: CORRECT\n",
      "AGGREGATOR: Liza Lapira's filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"\n"
     ]
    }
   ],
   "source": [
    "state = process_flow.invoke(initial_state, config={\"recursion_limit\": initial_state[\"recursion_limit\"]})\n",
    "prediction = state['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liza Lapira\\'s filmography includes the following notable roles: In 2009, she portrayed Sophie Trinh in the film \"Fast & Furious.\" The following year, in 2010, she played the role of Alva in the movie \"Repo Men.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In 2009, Liza Lapira played Sophie Trinh in the film Fast & Furious and Alva in the 2010 film Repo Men.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mid\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "llm.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 91980.35it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/chinonso/anaconda3/envs/lang2/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BleurtSPTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Using default tokenizer.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/chinonso/anaconda3/envs/lang2/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15-year-old Gauff beats 5-time Wimbledon champ Venus\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCori Gauff, 15, defeated Venus Williams at Wimbledon.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, score \u001b[38;5;129;01min\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Data-to-text-Agent/agents/evaluator.py:70\u001b[0m, in \u001b[0;36mevaluate_single\u001b[0;34m(references, prediction, sources)\u001b[0m\n\u001b[1;32m     67\u001b[0m     bleurt_output \u001b[38;5;241m=\u001b[39m bleurt_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# BERTScore (supports multiple references)\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m bert_out \u001b[38;5;241m=\u001b[39m \u001b[43mbertscore_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m bert_f1 \u001b[38;5;241m=\u001b[39m bert_out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU\u001b[39m\u001b[38;5;124m\"\u001b[39m: bleu,\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETEOR\u001b[39m\u001b[38;5;124m\"\u001b[39m: meteor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore-F1\u001b[39m\u001b[38;5;124m\"\u001b[39m: bert_f1\n\u001b[1;32m     82\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/lang2/lib/python3.10/site-packages/evaluate/module.py:467\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 467\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bertscore/cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b/bertscore.py:203\u001b[0m, in \u001b[0;36mBERTScore._compute\u001b[0;34m(self, predictions, references, lang, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached_bertscorer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_bertscorer\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;241m!=\u001b[39m hashcode:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_bertscorer \u001b[38;5;241m=\u001b[39m scorer(\n\u001b[1;32m    190\u001b[0m             model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[1;32m    191\u001b[0m             num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m             baseline_path\u001b[38;5;241m=\u001b[39mbaseline_path,\n\u001b[1;32m    201\u001b[0m         )\n\u001b[0;32m--> 203\u001b[0m (P, R, F) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcached_bertscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m output_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: P\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: R\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: F\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashcode\u001b[39m\u001b[38;5;124m\"\u001b[39m: hashcode,\n\u001b[1;32m    214\u001b[0m }\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/lang2/lib/python3.10/site-packages/bert_score/scorer.py:220\u001b[0m, in \u001b[0;36mBERTScorer.score\u001b[0;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[1;32m    217\u001b[0m     idf_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39msep_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    218\u001b[0m     idf_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mcls_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 220\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mbert_cos_score_idf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_group_boundaries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     max_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/lang2/lib/python3.10/site-packages/bert_score/utils.py:659\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    656\u001b[0m         ref_stats \u001b[38;5;241m=\u001b[39m pad_batch_stats(batch_refs, stats_dict, device)\n\u001b[1;32m    657\u001b[0m         hyp_stats \u001b[38;5;241m=\u001b[39m pad_batch_stats(batch_hyps, stats_dict, device)\n\u001b[0;32m--> 659\u001b[0m         P, R, F1 \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_cos_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mref_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyp_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m         preds\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mstack((P, R, F1), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m    661\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_layers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lang2/lib/python3.10/site-packages/bert_score/utils.py:528\u001b[0m, in \u001b[0;36mgreedy_cos_idf\u001b[0;34m(ref_embedding, ref_masks, ref_idf, hyp_embedding, hyp_masks, hyp_idf, all_layers)\u001b[0m\n\u001b[1;32m    525\u001b[0m sim \u001b[38;5;241m=\u001b[39m sim \u001b[38;5;241m*\u001b[39m masks\n\u001b[1;32m    527\u001b[0m word_precision \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 528\u001b[0m word_recall \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    530\u001b[0m hyp_idf\u001b[38;5;241m.\u001b[39mdiv_(hyp_idf\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    531\u001b[0m ref_idf\u001b[38;5;241m.\u001b[39mdiv_(ref_idf\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from agents.evaluator import evaluate_single\n",
    "\n",
    "scores = evaluate_single(ground_truth, prediction, data)\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir_path = \"results\"\n",
    "file_path = os.path.join(dir_path, \"result.json\")\n",
    "\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "if os.path.isdir(file_path):\n",
    "    raise IsADirectoryError(f\"Cannot write to '{file_path}' because it is a directory.\")\n",
    "\n",
    "# Recursively convert objects to serializable types\n",
    "def make_serializable(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return [make_serializable(x) for x in obj]    \n",
    "\n",
    "    elif hasattr(obj, \"model_dump\"):  # Pydantic BaseModel\n",
    "        return obj.model_dump()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: make_serializable(v) for k, v in obj.items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "serializable_state = make_serializable(dict(state))\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(serializable_state, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinonso/Data-to-text-Agent \n",
      " ['lang2.txt', 'image.png', 'workflow.ipynb', 'agents_modules_', 'flow.ipynb', '.git', 'README.md', 'requirements_lang_mac.txt', 'somto.txt', 'results', 'agents', 'requirements_lang2_mac.txt', 'smt.txt', 'requirements.txt', 'Rotowire.ipynb', 'LICENSE']\n",
      "/home/chinonso/Data-to-text-Agent/agents \n",
      " ['dataloader.py', 'llm_model.py', 'evaluator.py', 'agents_modules', 'agent_prompts.py', '__pycache__', '__init__.py', 'utilities']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"/home/chinonso/Data-to-text-Agent\", '\\n',os.listdir(\"/home/chinonso/Data-to-text-Agent\"))\n",
    "print(\"/home/chinonso/Data-to-text-Agent/agents\", '\\n', os.listdir(\"/home/chinonso/Data-to-text-Agent/agents\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'workers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m workers_list \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mworkers\u001b[49m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ——— Build your StateGraph ———\u001b[39;00m\n\u001b[1;32m      4\u001b[0m agent_workflow \u001b[38;5;241m=\u001b[39m StateGraph(StageExecute)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'workers' is not defined"
     ]
    }
   ],
   "source": [
    "workers_list = [key for key, value in workers.items()]\n",
    "\n",
    "# ——— Build your StateGraph ———\n",
    "agent_workflow = StateGraph(StageExecute)\n",
    "\n",
    "# 1) planner node\n",
    "# agent_workflow.add_node(\"planner\", Planner.run_model(Planner.create_model()))\n",
    "\n",
    "# 2) orchestrator node\n",
    "agent_workflow.add_node(\n",
    "    \"orchestrator\",\n",
    "    Orchestrator.run_model(Orchestrator.create_model(), workers=workers_list)\n",
    ")\n",
    "\n",
    "# 3) worker nodes\n",
    "#    here tools can be [] or any list of LangChain tools you have;\n",
    "#    initial_query is whatever you're passing in as the user input.\n",
    "tools = []\n",
    "initial_query = StageExecute[\"input\"]  # or whatever your entry payload is\n",
    "worker_names = add_workers(workers, agent_workflow, tools, initial_query)\n",
    "agent_workflow.add_node(\"inspector\", Inspector.run_model(Inspector.create_model()))\n",
    "agent_workflow.add_node(\"evaluator\", Inspector.run_model(Inspector.create_model()))\n",
    "agent_workflow.add_node(\"aggregator\", ResponseAggregator.run_model(ResponseAggregator.create_model()))\n",
    "\n",
    "\n",
    "# 4) wire up the edges\n",
    "#  start → planner → orchestrator\n",
    "# agent_workflow.add_edge(START, \"planner\")\n",
    "# agent_workflow.add_edge(\"planner\", \"orchestrator\")\n",
    "agent_workflow.add_edge(START, \"orchestrator\")\n",
    "\n",
    "#  orchestrator uses the \"next\" field in state to pick which worker to run\n",
    "#  we map each worker name to itself, and FINISH to END\n",
    "conditional_map = {name: name for name in worker_names}\n",
    "conditional_map[\"inspector\"] = \"inspector\"  # Add inspector explicitly\n",
    "\n",
    "agent_workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    lambda state: state[\"next\"],\n",
    "    conditional_map\n",
    ")\n",
    "\n",
    "#  after a worker runs, end the graph\n",
    "for name in worker_names:\n",
    "    agent_workflow.add_edge(name, \"inspector\")\n",
    "    \n",
    "agent_workflow.add_conditional_edges(\"inspector\", transition_after_inspection)\n",
    "agent_workflow.add_edge(\"evaluator\", \"inspector\")\n",
    "agent_workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "#  set the entry point\n",
    "# agent_workflow.set_entry_point(\"planner\")\n",
    "agent_workflow.set_entry_point(\"orchestrator\")\n",
    "\n",
    "#  compile into a runnable app\n",
    "process_flow = agent_workflow.compile()\n",
    "\n",
    "display(Image(process_flow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# rotowire = load_dataset(\"mrm8488/rotowire-sbnation\")\n",
    "# turku_hockey = datasets.load_dataset('GEM/turku_hockey_data2text')\n",
    "# totto = datasets.load_dataset('GEM/totto')\n",
    "# basketball = datasets.load_dataset('GEM/sportsett_basketball')\n",
    "# webnlg = datasets.load_dataset('GEM/web_nlg', 'en')\n",
    "# weather = datasets.load_dataset('GEM/conversational_weather')\n",
    "# dart = datasets.load_dataset('GEM/dart')\n",
    "# mlb = datasets.load_dataset('GEM/mlb_data_to_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.graph import START, END, StateGraph\n",
    "# from utils import StageExecute, Agent, AgentExecuteInput\n",
    "# from IPython.display import Image, SVG, display\n",
    "# from typing import List, Literal, Optional, Text, Union, Dict, Any\n",
    "\n",
    "# class Planner:\n",
    "#     def create_model(self, task):\n",
    "#         # Logic to generate plans\n",
    "#         pass\n",
    "#     @classmethod\n",
    "#     def run_model(cls,):\n",
    "\n",
    "#         pass\n",
    "\n",
    "# class Orchestrator:\n",
    "#     def create_model(self, task):\n",
    "#         # Logic to generate plans\n",
    "#         pass\n",
    "#     @classmethod\n",
    "#     def run_model(cls,):\n",
    "\n",
    "#         pass\n",
    "\n",
    "# class Worker:\n",
    "#     def create_model(self, task):\n",
    "#         # Logic to generate plans\n",
    "#         pass\n",
    "#     @classmethod\n",
    "#     def run_model(cls,):\n",
    "\n",
    "#         pass\n",
    "\n",
    "# class Inspector:\n",
    "#     def create_model(self, task):\n",
    "#         # Logic to generate plans\n",
    "#         pass\n",
    "#     @classmethod\n",
    "#     def run_model(cls,):\n",
    "\n",
    "#         pass\n",
    "\n",
    "# class ResponseAggregator:\n",
    "#     def create_model(self, task):\n",
    "#         # Logic to generate plans\n",
    "#         pass\n",
    "#     @classmethod\n",
    "#     def run_model(cls,):\n",
    "\n",
    "#         pass\n",
    "    \n",
    "# def transition_after_inspection(state: StageExecute) -> Literal[\"orchestrator\", \"aggregator\"]:\n",
    "#     \"\"\"Decides the next stage after inspection based on task correctness.\"\"\"\n",
    "#     if \"aggregator\" in state and state[\"aggregator\"]:\n",
    "#         return \"aggregator\"\n",
    "#     else:\n",
    "#         return \"orchestrator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers = [\"worker1\", \"worker2\"]  # Example workers\n",
    "# conditional_map = {worker: \"inspector\" for worker in workers}\n",
    "\n",
    "# agent_workflow = StateGraph(StageExecute)\n",
    "# agent_workflow.add_node(\"planner\", Planner.run_model)\n",
    "# agent_workflow.add_node(\"orchestrator\", Orchestrator.run_model)\n",
    "# agent_workflow.add_node(\"worker\", Worker.run_model)\n",
    "# agent_workflow.add_node(\"inspector\", Inspector.run_model)\n",
    "# agent_workflow.add_node(\"aggregator\", ResponseAggregator.run_model)\n",
    "\n",
    "# agent_workflow.add_edge(START, \"planner\")\n",
    "# agent_workflow.add_edge(\"planner\", \"orchestrator\")\n",
    "# agent_workflow.add_edge(\"orchestrator\", \"worker\")\n",
    "# agent_workflow.add_edge(\"worker\", \"inspector\")\n",
    "# agent_workflow.add_conditional_edges(\"inspector\", transition_after_inspection)\n",
    "# agent_workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "# process_flow = agent_workflow.compile()\n",
    "\n",
    "# display(Image(process_flow.get_graph(xray=True).draw_mermaid_png()))\n",
    "# # display(SVG(process_flow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # workers = [\"worker1\", \"worker2\"]  # Example workers\n",
    "# conditional_map = {worker: \"inspector\" for worker in workers.keys()}\n",
    "\n",
    "# def add_workers(tools= , query= , task_name):\n",
    "# for task_name, task_description in workers.items():\n",
    "    \n",
    "\n",
    "# agent_workflow = StateGraph(StageExecute)\n",
    "# agent_workflow.add_node(\"planner\", Planner.run_model(Planner.create_model()))\n",
    "# agent_workflow.add_node(\"orchestrator\", Orchestrator.run_model(Orchestrator.create_model(), workers=workers_list))\n",
    "# agent_workflow.add_node(\"worker\", Worker.run_model(Worker.create_model(tools=workers_list, query=StageExecute[\"input\"]), task_name=))\n",
    "# # agent_workflow.add_node(\"inspector\", Inspector.run_model)\n",
    "# # agent_workflow.add_node(\"aggregator\", ResponseAggregator.run_model)\n",
    "\n",
    "# agent_workflow.add_edge(START, \"planner\")\n",
    "# agent_workflow.add_edge(\"planner\", \"orchestrator\")\n",
    "# agent_workflow.add_edge(\"orchestrator\", \"worker\")\n",
    "# agent_workflow.add_edge(\"worker\", END)\n",
    "# # agent_workflow.add_edge(\"worker\", \"inspector\")\n",
    "# # # agent_workflow.add_edge(\"inspector\", \"orchestrator\")\n",
    "# # agent_workflow.add_conditional_edges(\"inspector\", transition_after_inspection)\n",
    "# # agent_workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "# process_flow = agent_workflow.compile()\n",
    "\n",
    "# # display(Image(process_flow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers = {\n",
    "#     \"content selection\": (\n",
    "#         \"The Content Selection agent is responsible for analyzing the raw input data, identifying the key \"\n",
    "#         \"elements and relevant features that will form the backbone of the final text output. This agent \"\n",
    "#         \"meticulously scans through tables, XML, or any structured data provided, and it distinguishes between \"\n",
    "#         \"important information and peripheral details. Its tasks include filtering out noise, determining \"\n",
    "#         \"salient content based on context, and ensuring that no essential data points are missed. The output \"\n",
    "#         \"from this agent provides a curated list of information that will serve as the foundation for generating \"\n",
    "#         \"a coherent and accurate text narrative.\"\n",
    "#     ),\n",
    "#     \"text structuring\": (\n",
    "#         \"The Text Structuring agent is tasked with taking the curated content from the Content Selection agent \"\n",
    "#         \"and organizing it into a fluid and engaging narrative. This agent focuses on the arrangement, flow, \"\n",
    "#         \"and logical segmentation of the text to ensure that the final output is not only accurate but also easily \"\n",
    "#         \"comprehensible and well-structured. It works by mapping out the overall framework of the narrative, \"\n",
    "#         \"allocating content into sections, and applying linguistic transformations that enhance readability. \"\n",
    "#         \"Its work ensures that the text is not a mere aggregation of data points, but a well-crafted piece \"\n",
    "#         \"that reflects both the detailed insights of the data and the clarity required for a high-quality narrative.\"\n",
    "#     ),\n",
    "#     \"surface realization\": (\n",
    "#         \"The Surface Realization agent is responsible for generating fluent and grammatically correct natural language \"\n",
    "#         \"text from the structured and organized content provided by the previous stages. It combines the selected content \"\n",
    "#         \"and structured layout to form complete sentences, using appropriate lexical choices, syntactic constructions, \"\n",
    "#         \"and discourse markers. This agent ensures that the final text adheres to linguistic norms, maintains coherence, \"\n",
    "#         \"and reads naturally as if written by a human.\"\n",
    "#     )\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
