{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinonso/anaconda3/envs/lang2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Literal, Optional, Text, Union, Dict, Any\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph_mermaid import MermaidDrawMethod\n",
    "from agents.agents_modules.workflow import build_agent_workflow\n",
    "from agents.dataloader import load_dataset_by_name, extract_example\n",
    "from agents.utilities.agent_utils import save_result_to_json\n",
    "from agents.llm_model import UnifiedModel, model_name\n",
    "from agents.agent_prompts import END_TO_END_GENERATION_PROMPT, input_prompt #,CONTENT_SELECTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"openai\" #ollama, openai, hf, aixplain\n",
    "process_flow = build_agent_workflow(provider=provider)\n",
    "# display(Image(process_flow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: webnlg_hf\n",
      "Size: 1779\n",
      "========== INPUT DATA ==========\n",
      "['Aleksandr_Prudnikov | club | FC_Amkar_Perm', 'Aleksandr_Prudnikov | birthDate | 1989-02-24', 'Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow', 'Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm']\n",
      "\n",
      "========== TARGET (if any) ==========\n",
      "Aleksandr Prudnikov was born on 1989-02-24 and plays for FC Amkar Perm. He was also a member of the youth side of FC Spartak Moscow.\n",
      "\n",
      "========== GROUND TRUTH REFERENCES ==========\n",
      "['Aleksandr Prudnikov was born on 1989-02-24 and plays for FC Amkar Perm. He was also a member of the youth side of FC Spartak Moscow.', \"Aleksandr Prudnikov from the FC Amkar Perm club, born 1989-02-24 played for FC Spartak Moscow's youth team.\", 'Aleksandr Prudnikov, born on 24th February 1989, and whose youth football club was FC Spartak Moscow, currently plays for the FC Amkar Perm football club.']\n"
     ]
    }
   ],
   "source": [
    "# from agents.dataloader import load_dataset_by_name, extract_example\n",
    "# Exclude turku_hockey and conversational_weather\n",
    "# totto, webnlg, dart, rotowire, sportsett_basketball, mlb\n",
    "name = \"webnlg_hf\"\n",
    "num = 532 # Sample id 1037\n",
    "set = \"test\"\n",
    "\n",
    "data = load_dataset_by_name(name)\n",
    "dataset = data[set]\n",
    "sample = extract_example(name, data[set][num])\n",
    "data = sample.get('input', '')\n",
    "ground_truth = sample.get('references', \"\")\n",
    "target = sample.get('target', \"\")\n",
    "\n",
    "print(f\"Size: {len(dataset)}\")\n",
    "print(\"========== INPUT DATA ==========\")\n",
    "print(f\"{data}\\n\")\n",
    "print(\"========== TARGET (if any) ==========\")\n",
    "print(f\"{target}\\n\")\n",
    "print(\"========== GROUND TRUTH REFERENCES ==========\")\n",
    "print(f\"{ground_truth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORCHESTRATOR OUTPUT: Thought: The user has provided a set of RDF-like triples about Aleksandr Prudnikov, including his club, birth date, youth club, and current club. There is no prior pipeline history or guardrail feedback, so I must begin at the first stage: Content Ordering. My goal is to organize the information logically, ensuring a coherent narrative structure for the subsequent stages. Typically, biographical data is best presented in chronological or logical order: birth date, youth club, club history, and current club. I will instruct the content ordering worker to arrange the data in a way that supports a natural, readable biography, without omitting any field or introducing hallucinated information.\n",
      "\n",
      "Worker: content ordering\n",
      "Worker Input: \n",
      "Original data: \n",
      "['Aleksandr_Prudnikov | club | FC_Amkar_Perm', 'Aleksandr_Prudnikov | birthDate | 1989-02-24', 'Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow', 'Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm']\n",
      "\n",
      "Instructions:\n",
      "- Organize the provided data into a logical order suitable for generating a coherent biographical text about Aleksandr Prudnikov.\n",
      "- Typically, start with birth date, then youth club, followed by club history, and finally current club.\n",
      "- Do not omit any information or add any new facts.\n",
      "- The output should be a clearly ordered list of the data fields, ready for the next stage of text structuring.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": [\n",
      "    \"Aleksandr_Prudnikov | birthDate | 1989-02-24\",\n",
      "    \"Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow\",\n",
      "    \"Aleksandr_Prudnikov | club | FC_Amkar_Perm\",\n",
      "    \"Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm\"\n",
      "  ]\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "CORRECT\n",
      "ORCHESTRATOR OUTPUT: Thought: The content ordering stage has been completed correctly, as confirmed by the guardrail feedback labeled 'CORRECT'. The data is now logically ordered for biographical text generation. According to the workflow policy, I must now proceed to the next stage, which is text structuring. I will provide the text structuring worker with the original data, the ordered list from the previous stage, and clear instructions to organize the information into a coherent paragraph structure, ensuring that no information is omitted or added.\n",
      "\n",
      "Worker: text structuring\n",
      "\n",
      "Worker Input: \n",
      "Original data: \n",
      "['Aleksandr_Prudnikov | club | FC_Amkar_Perm', 'Aleksandr_Prudnikov | birthDate | 1989-02-24', 'Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow', 'Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm']\n",
      "\n",
      "Ordered data (from content ordering): \n",
      "['Aleksandr_Prudnikov | birthDate | 1989-02-24', 'Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow', 'Aleksandr_Prudnikov | club | FC_Amkar_Perm', 'Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm']\n",
      "\n",
      "Instructions:\n",
      "- Structure the ordered data into a coherent paragraph suitable for a biographical entry about Aleksandr Prudnikov.\n",
      "- Ensure each data point is clearly represented in the structure.\n",
      "- Do not omit any information or add any new facts.\n",
      "- The output should be a structured paragraph (not yet fully realized text), clearly indicating how each data field will be incorporated into the final text.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"<paragraph>\\n  <snt>\\n    Aleksandr_Prudnikov | birthDate | 1989-02-24\\n  </snt>\\n  <snt>\\n    Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow\\n  </snt>\\n  <snt>\\n    Aleksandr_Prudnikov | club | FC_Amkar_Perm\\n    Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm\\n  </snt>\\n</paragraph>\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "CORRECT\n",
      "ORCHESTRATOR OUTPUT: Thought: The guardrail feedback for the text structuring stage is \"CORRECT,\" indicating that the structured paragraph accurately represents all data points and is suitable for the next stage. According to the workflow policy, I must now proceed to the Surface Realization stage. I will provide the surface realization worker with the original data, the structured paragraph, and clear instructions to generate a fluent, coherent, and grammatically correct biographical text about Aleksandr Prudnikov, ensuring that all information is included and no hallucinations occur.\n",
      "\n",
      "Worker: surface realization\n",
      "\n",
      "Worker Input: \n",
      "Original data: \n",
      "['Aleksandr_Prudnikov | club | FC_Amkar_Perm', 'Aleksandr_Prudnikov | birthDate | 1989-02-24', 'Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow', 'Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm']\n",
      "\n",
      "Structured paragraph (from text structuring): \n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Aleksandr_Prudnikov | birthDate | 1989-02-24\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Aleksandr_Prudnikov | youthclub | FC_Spartak_Moscow\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Aleksandr_Prudnikov | club | FC_Amkar_Perm\n",
      "    Aleksandr_Prudnikov | currentclub | FC_Amkar_Perm\n",
      "  </snt>\n",
      "</paragraph>\n",
      "\n",
      "Instructions:\n",
      "- Generate a fluent, coherent, and grammatically correct paragraph suitable for a biographical entry about Aleksandr Prudnikov.\n",
      "- Ensure that all information from the structured paragraph is included: his birth date, youth club, club, and current club.\n",
      "- Do not omit any data or add any information not present in the original input.\n",
      "- The output should be a single, well-formed paragraph that reads naturally and clearly presents all facts.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Aleksandr Prudnikov was born on February 24, 1989. He began his football career with the youth club FC Spartak Moscow. He has played for FC Amkar Perm, which is also his current club.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=== GUARDRAIL REVIEW (surface realization) ===\n",
      "[Fluency & Grammar]: CORRECT\n",
      "[Faithfulness & Adequacy]: CORRECT\n",
      "[Coherence & Naturalness]: CORRECT\n",
      "OVERALL: CORRECT\n",
      "FINALIZER: Aleksandr Prudnikov was born on February 24, 1989. He began his football career with the youth club FC Spartak Moscow. He has played for FC Amkar Perm, which is also his current club.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"You are an agent designed to generate text from data for a data-to-text natural language generation. You can be provided data in the form of xml, table, meaning representations, graphs etc. \n",
    "Your task is to generate the appropriate text given the data information without omitting any field or adding extra information in essence called hallucination.\n",
    "\n",
    "Dataset: {'webnlg' if name == 'webnlg_hf' else name}\n",
    "Here is the data, generate text using the provided data:\n",
    "{data}\"\"\"\n",
    "\n",
    "initial_state = {\n",
    "    \"user_prompt\": query,\n",
    "    \"raw_data\": data,\n",
    "    \"history_of_steps\": [],\n",
    "    \"final_response\": \"\",\n",
    "    \"next_agent\": \"\",\n",
    "    \"next_agent_payload\": \"\",\n",
    "    \"current_step\": 0,\n",
    "    \"iteration_count\": 0,\n",
    "    \"max_iteration\": 100,\n",
    "}\n",
    "\n",
    "state = process_flow.invoke(initial_state, config={\"recursion_limit\": initial_state[\"max_iteration\"]})\n",
    "prediction = state['final_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Agent result saved to: results/webnlg_hf/webnlg_hf_1710.json\n"
     ]
    }
   ],
   "source": [
    "# save_result_to_json(state, dataset_folder=f\"{name}\", filename=f\"{name}_{num}.json\")\n",
    "# save_result_to_json(state, filename=f\"webnlg_long.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleksandr Prudnikov was born on February 24, 1989. He began his football career with the youth club FC Spartak Moscow. He has played for FC Amkar Perm, which is also his current club.\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aleksandr Prudnikov was born on 1989-02-24 and plays for FC Amkar Perm. He was also a member of the youth side of FC Spartak Moscow.',\n",
       " \"Aleksandr Prudnikov from the FC Amkar Perm club, born 1989-02-24 played for FC Spartak Moscow's youth team.\",\n",
       " 'Aleksandr Prudnikov, born on 24th February 1989, and whose youth football club was FC Spartak Moscow, currently plays for the FC Amkar Perm football club.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lady Anne Monson, a British national was born on January 1, 1726 in Darlington, in the Kingdom of England. She died on February 18th, 1776.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 23:05:32.962986: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-02 23:05:32.970568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751493932.979431 1383944 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751493932.982188 1383944 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751493932.989314 1383944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751493932.989323 1383944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751493932.989323 1383944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751493932.989324 1383944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-02 23:05:32.992182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 62788.98it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/chinonso/anaconda3/envs/lang2/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BleurtSPTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Using default tokenizer.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 5080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.3097\n",
      "METEOR: 0.7582\n",
      "ROUGE-F1: 0.6210\n",
      "COMET: 0.8750\n",
      "BLEURT: 0.6713\n",
      "BERTScore-F1: 0.9579\n"
     ]
    }
   ],
   "source": [
    "from agents.evaluator import evaluate_single\n",
    "\n",
    "scores = evaluate_single(target, prediction, data)\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def build_d2t_prompt(name, num_examples, input_data, samples_file=\"random_train_samples.json\"):\n",
    "#     \"\"\"\n",
    "#     Build a few-shot prompt for data-to-text generation.\n",
    "\n",
    "#     Args:\n",
    "#         name (str): Dataset name to filter (e.g., \"totto\").\n",
    "#         num_examples (int): Number of examples to include.\n",
    "#         input_data (str): The data string for the query Data: ... block.\n",
    "#         samples_file (str): Path to random samples JSON.\n",
    "\n",
    "#     Returns:\n",
    "#         str: Prompt string ready for use.\n",
    "#     \"\"\"\n",
    "#     with open(samples_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#         results = json.load(f)\n",
    "\n",
    "#     filtered = [\n",
    "#         ex for ex in results\n",
    "#         if ex.get(\"dataset\") == name and ex.get(\"input\", \"\").strip()\n",
    "#         and (ex.get(\"target\", \"\").strip() or (ex.get(\"references\") and any(r.strip() for r in ex[\"references\"])))\n",
    "#     ]\n",
    "\n",
    "#     examples = filtered[:num_examples]\n",
    "#     if len(examples) < num_examples:\n",
    "#         print(f\"Only {len(examples)} examples found for dataset '{name}'\")\n",
    "\n",
    "#     prompt_blocks = []\n",
    "#     for i, ex in enumerate(examples, 1):\n",
    "#         input_text = ex.get(\"input\", \"\").strip()\n",
    "#         output = ex.get(\"target\", \"\").strip()\n",
    "#         if not output:\n",
    "#             refs = [r.strip() for r in ex.get(\"references\", []) if r.strip()]\n",
    "#             output = refs[0] if refs else \"\"\n",
    "#         prompt_blocks.append(f\"Example {i}:\\nData: {input_text}\\nOutput: {output}\\n\")\n",
    "\n",
    "#     prompt_examples = \"\\n\".join(prompt_blocks)\n",
    "\n",
    "#     prompt_template = f\"\"\"You are an agent designed to generate text from data for a data-to-text natural language generation. \n",
    "# You can be provided data in the form of xml, table, meaning representations, graphs etc.\n",
    "# Your task is to generate the appropriate text given the data information without omitting any field or adding extra information in essence called hallucination.\n",
    "\n",
    "# Dataset: {'webnlg' if name == 'webnlg_hf' else name}\n",
    "\n",
    "# Examples:\n",
    "# {prompt_examples}\n",
    "\n",
    "# Here is the data, now generate text using the provided data:\n",
    "\n",
    "# Data: {input_data}\n",
    "# Output: \"\"\"\n",
    "#     return prompt_template\n",
    "\n",
    "# # Example usage:\n",
    "# prompt = build_d2t_prompt(\"totto\", 5, data)\n",
    "# print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = model_name.get(provider.lower(), {}).copy()\n",
    "# conf[\"temperature\"] = 0.0\n",
    "# llm = UnifiedModel(provider=provider, **conf).model_(CONTENT_SELECTION_PROMPT)\n",
    "# CS_prediction = llm.invoke({'input': data}).content.strip()\n",
    "# print(CS_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"\"\"[['Lagos', 'areaLand', '999600000.0'],\n",
    "#  ['Lagos', 'areaMetro', '2706700000.0'],\n",
    "#  ['Lagos', 'areaUrban', '907000000.0'],\n",
    "#  ['Lagos', 'populationMetro', '21320000'],\n",
    "#  ['Lagos', 'populationMetroDensity', '7759.0'],\n",
    "#  ['Lagos', 'areaMetro', '2706.7'],\n",
    "#  ['Lagos', 'areaTotal', '1171.28'],\n",
    "#  ['Lagos', 'areaUrban', '907.0'],\n",
    "#  ['Lagos', 'populationDensity', '6871.0'],\n",
    "#  ['Lagos', 'populationMetroDensity', '7759.0'],\n",
    "#  ['Lagos', 'areaCode', '010'],\n",
    "#  ['Lagos', 'areaTotal', '1171280000.0'],\n",
    "#  ['Lagos', 'demonym', 'Lagosian'],\n",
    "#  ['Lagos', 'motto', 'Èkó ò ní bàjé o!'],\n",
    "#  ['Lagos', 'populationDensity', '6871.0'],\n",
    "#  ['Lagos', 'populationTotal', '8048430'],\n",
    "#  ['Lagos', 'utcOffset', '+1'],\n",
    "#  ['Lagos', 'country', 'Nigeria'],\n",
    "#  ['Lagos', 'founder', 'Awori_tribe'],\n",
    "#  ['Lagos', 'timeZone', 'West_Africa_Time'],\n",
    "#  ['Benfruit_Plant', 'location', 'Lagos'],\n",
    "#  ['Nigerian_Institute_of_Management', 'location', 'Lagos'],\n",
    "#  ['Before_30', 'location', 'Lagos'],\n",
    "#  ['Reduction_of_Lagos', 'place', 'Lagos'],\n",
    "#  [\"Cait_O'Riordan\", 'birthPlace', 'Lagos'],\n",
    "#  ['Candy_Augustine_Agbane', 'birthPlace', 'Lagos'],\n",
    "#  ['Carol_King_(actress)', 'birthPlace', 'Lagos'],\n",
    "#  ['Amusa_Shittu', 'deathPlace', 'Lagos'],\n",
    "#  ['Samuel_Ajayi_Crowther', 'deathPlace', 'Lagos'],\n",
    "#  ['Samuel_Johnson_(Nigerian_historian)', 'deathPlace', 'Lagos'],\n",
    "#  ['Dobox', 'foundationPlace', 'Lagos'],\n",
    "#  ['IROKO_Partners', 'foundationPlace', 'Lagos'],\n",
    "#  ['Isaac_Fola-Alade', 'significantBuilding', 'Lagos'],\n",
    "#  ['Olufemi_Majekodunmi', 'significantBuilding', 'Lagos'],\n",
    "#  ['Cally_Air', 'targetAirport', 'Lagos'],\n",
    "#  ['Ibom_Air', 'targetAirport', 'Lagos'],\n",
    "#  ['Max_Air', 'targetAirport', 'Lagos'],\n",
    "#  ['Isaac_Fola-Alade', 'significantProject', 'Lagos'],\n",
    "#  ['ADC_Airlines', 'hubAirport', 'Lagos'],\n",
    "#  ['Babington_Macaulay_Junior_Seminary', 'state', 'Lagos'],\n",
    "#  ['Government_College_Ikorodu', 'state', 'Lagos'],\n",
    "#  ['Ebun_Oluwa_Pro_Veritas', 'state', 'Lagos'],\n",
    "#  ['Colonial_Nigeria', 'capital', 'Lagos'],\n",
    "#  ['Federation_of_Nigeria', 'capital', 'Lagos'],\n",
    "#  ['Lagos_Colony', 'capital', 'Lagos'],\n",
    "#  ['African_Union', 'largestCity', 'Lagos'],\n",
    "#  ['Nigeria', 'largestCity', 'Lagos'],\n",
    "#  ['Military_dictatorship_in_Nigeria', 'largestCity', 'Lagos'],\n",
    "#  ['Volkswagen_Beetle', 'assembly', 'Lagos'],\n",
    "#  ['Volkswagen_Jetta_(A2)', 'assembly', 'Lagos'],\n",
    "#  ['Isuzu_Forward', 'assembly', 'Lagos'],\n",
    "#  ['Juliet_Ibrahim', 'award', 'Lagos'],\n",
    "#  ['Benin-Ore-Shagamu_Expressway', 'city', 'Lagos'],\n",
    "#  ['Encomium_Magazine', 'city', 'Lagos'],\n",
    "#  ['Bogobiri_House', 'city', 'Lagos'],\n",
    "#  ['Sub-Saharan_Africa', 'country', 'Lagos'],\n",
    "#  ['Desmond_Majekodunmi', 'education', 'Lagos'],\n",
    "#  ['Buchi_Emecheta', 'education', 'Lagos'],\n",
    "#  ['Habeeb_Okunola', 'education', 'Lagos'],\n",
    "#  ['MFM_F.C.', 'ground', 'Lagos'],\n",
    "#  ['ACB_Lagos_F.C.', 'ground', 'Lagos'],\n",
    "#  ['COD_United_F.C.', 'ground', 'Lagos'],\n",
    "#  ['Caritas_Communications', 'headquarter', 'Lagos'],\n",
    "#  ['Nigerian_Accounting_Association', 'headquarter', 'Lagos'],\n",
    "#  ['Merchant_Express_Aviation', 'headquarter', 'Lagos'],\n",
    "#  ['Sasha_P', 'hometown', 'Lagos'],\n",
    "#  ['Davina_Oriakhi', 'hometown', 'Lagos'],\n",
    "#  ['VanJess', 'hometown', 'Lagos'],\n",
    "#  ['Olu_Amoda', 'knownFor', 'Lagos'],\n",
    "#  ['Toki_Mabogunje', 'knownFor', 'Lagos'],\n",
    "#  ['United_Africa_Company_of_Nigeria', 'locationCity', 'Lagos'],\n",
    "#  ['Promasidor_Nigeria', 'locationCity', 'Lagos'],\n",
    "#  ['G-Worldwide_Entertainment', 'locationCity', 'Lagos'],\n",
    "#  ['LADOL', 'locationCountry', 'Lagos'],\n",
    "#  ['Atlantic_Ocean', 'nearestCity', 'Lagos'],\n",
    "#  ['Lagos_Lagoon', 'nearestCity', 'Lagos'],\n",
    "#  ['Let_Me_Roll_It', 'recordedIn', 'Lagos'],\n",
    "#  ['Mamunia', 'recordedIn', 'Lagos'],\n",
    "#  ['Band_on_the_Run_(song)', 'recordedIn', 'Lagos'],\n",
    "#  ['First_Consultant_Hospital', 'region', 'Lagos'],\n",
    "#  ['National_Orthopaedic_Hospital,_Igbobi', 'region', 'Lagos'],\n",
    "#  ['GIG_Mobility', 'regionServed', 'Lagos'],\n",
    "#  ['TEDxLagos', 'regionServed', 'Lagos'],\n",
    "#  ['Patrick_Utomi', 'residence', 'Lagos'],\n",
    "#  ['Dakuku_Peterside', 'residence', 'Lagos'],\n",
    "#  ['Mudashiru_Obasa', 'residence', 'Lagos']]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagos_86 = \"\"\"Lagos is located in Nigeria, and its inhabitants are known as Lagosians. The city's motto is 'Èkó ò ní bàjé o!' and it was founded by the Awori tribe. Lagos operates on West Africa Time, with a UTC offset of +1. The land area of Lagos covers 999.6 square kilometers, with the urban area measuring 907 square kilometers, while the metropolitan area spans 2,706.7 square kilometers. The total area of the city is 1,171.28 square kilometers. Lagos has a population of 8,048,430, with a population density of 6,871 people per square kilometer, while the metropolitan population reaches 21,320,000 with a metro density of 7,759 per square kilometer. The city's area code is 010.\n",
    "\n",
    "# The Atlantic Ocean and Lagos Lagoon are closest to Lagos. It is recognized as the largest city within the African Union, Nigeria, and during the Military dictatorship in Nigeria. Lagos has also served as the capital of Colonial Nigeria, the Federation of Nigeria, and the Lagos Colony. In Sub-Saharan Africa, Lagos is counted among its prominent cities.\n",
    "\n",
    "# Numerous institutions and organizations are based in Lagos, such as Benfruit Plant, the Nigerian Institute of Management, and Before 30. The city is also the foundation place of Dobox and IROKO Partners. Companies like Caritas Communications, the Nigerian Accounting Association, and Merchant Express Aviation have their headquarters in Lagos. The United Africa Company of Nigeria, Promasidor Nigeria, and G-Worldwide Entertainment are all located in the city. LADOL is also situated in Lagos. Lagos serves as the region for GIG Mobility and TEDxLagos, as well as for First Consultant Hospital and National Orthopaedic Hospital, Igbobi. Notable locations like the Benin-Ore-Shagamu Expressway, Encomium Magazine, and Bogobiri House are found here, and educational institutions such as Babington Macaulay Junior Seminary, Government College Ikorodu, and Ebun Oluwa Pro Veritas are located within Lagos State. Lagos is home to the grounds of MFM F.C., ACB Lagos F.C., and COD United F.C., and is associated with the assembly of vehicles like the Volkswagen Beetle, Volkswagen Jetta (A2), and Isuzu Forward. The city is known for significant buildings designed by Isaac Fola-Alade and Olufemi Majekodunmi, as well as a significant project by Isaac Fola-Alade. Music recordings such as 'Let Me Roll It', 'Mamunia', and 'Band on the Run' were recorded in Lagos. The city is notable for the historic Reduction of Lagos, and features as a target airport for airlines including Cally Air, Ibom Air, and Max Air, while also serving as a hub for ADC Airlines.\n",
    "\n",
    "# Lagos is the hometown of personalities such as Sasha P, Davina Oriakhi, and VanJess. It is likewise the birthplace of Cait O'Riordan, Candy Augustine Agbane, and Carol King the actress. The city is where figures like Amusa Shittu, Samuel Ajayi Crowther, and Samuel Johnson, the Nigerian historian, passed away. It is home to residents including Patrick Utomi, Dakuku Peterside, and Mudashiru Obasa. Individuals such as Olu Amoda and Toki Mabogunje are known for their connections to Lagos. The city is where Desmond Majekodunmi, Buchi Emecheta, and Habeeb Okunola received their education, and Juliet Ibrahim is among those who have received awards in Lagos.\"\"\"\n",
    "\n",
    "# print(lagos_86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# src = \"results/webnlg_e2e.json\"\n",
    "# src_path = Path(src)\n",
    "# dst_path = Path(src.split('.')[0])\n",
    "\n",
    "# with src_path.open(encoding=\"utf-8\") as src, dst_path.open(\"w\", encoding=\"utf-8\") as dst:\n",
    "#     for lineno, line in enumerate(src, 1):\n",
    "#         line = line.strip()\n",
    "#         if not line:          # skip blank lines\n",
    "#             continue\n",
    "#         try:\n",
    "#             obj = json.loads(line)\n",
    "#         except json.JSONDecodeError as exc:\n",
    "#             print(f\"⚠️  skip line {lineno}: {exc}\")\n",
    "#             continue\n",
    "\n",
    "#         # Normalise whitespace: collapse any CR/LF runs to a single space\n",
    "#         pred = \" \".join(obj.get(\"prediction\", \"\").replace(\"\\n\", \" \").split())\n",
    "#         if pred:\n",
    "#             dst.write(pred + \"\\n\")\n",
    "\n",
    "# print(f\"Finished – cleaned predictions saved to {dst_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "# from agents.dataloader import load_dataset_by_name, extract_example\n",
    "\n",
    "# datasets = [\"totto\", \"webnlg_hf\", \"dart\", \"rotowire\", \"sportsett_basketball\", \"mlb\"]\n",
    "# samples_per_dataset = 5\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for name in datasets:\n",
    "#     data = load_dataset_by_name(name)\n",
    "#     dataset = data[\"train\"]\n",
    "#     indices = random.sample(range(len(dataset)), min(samples_per_dataset, len(dataset)))\n",
    "#     for idx in indices:\n",
    "#         sample = extract_example(name, dataset[idx])\n",
    "#         results.append({\n",
    "#             \"dataset\": 'webnlg' if name=='webnlg_hf' else name,\n",
    "#             \"input\": sample.get(\"input\", \"\"),\n",
    "#             \"target\": sample.get(\"target\", \"\"),\n",
    "#             \"references\": sample.get(\"references\", [])\n",
    "#         })\n",
    "\n",
    "# with open(\"random_train_samples.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(\"Saved to random_train_samples.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Data:\n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Acharya_Institute_of_Technology | campus | \"In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090.\"\n",
      "    Acharya_Institute_of_Technology | city | Bangalore\n",
      "    Acharya_Institute_of_Technology | state | Karnataka\n",
      "    Acharya_Institute_of_Technology | country | \"India\"\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Acharya_Institute_of_Technology | established | 2000\n",
      "    Acharya_Institute_of_Technology | motto | \"Nurturing Excellence\"\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Acharya_Institute_of_Technology | affiliation | Visvesvaraya_Technological_University\n",
      "  </snt>\n",
      "</paragraph>\n",
      "Output:\n",
      "The location of the Acharya Institute of Technology is \"In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090.\" The Institute was established in 2000 in the state of Karnataka, India and has the motto \"Nurturing Excellence. It is affiliated with the Visvesvaraya Technological University.\n",
      "\n",
      "Example 2:\n",
      "Data:\n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Akeem_Dent | debutTeam | Atlanta_Falcons\n",
      "    Atlanta_Falcons | owner | Arthur_Blank\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Akeem_Dent | formerTeam | Houston_Texans\n",
      "    Houston_Texans | city | Texas\n",
      "  </snt>\n",
      "</paragraph>\n",
      "Output:\n",
      "Akeem Dent debuted with the Atlanta Falcons who are owned by Arthur Blank. He went on to play for Houston Texans who are based in Texas.\n",
      "\n",
      "Example 3:\n",
      "Data:\n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Atlanta | isPartOf | DeKalb_County,_Georgia\n",
      "    Atlanta | country | United_States\n",
      "    United_States | ethnicGroup | Native_Americans_in_the_United_States\n",
      "  </snt>\n",
      "</paragraph>\n",
      "Output:\n",
      "Most of Atlanta is part of DeKalb County in Georgia, in the United States, where Native Americans are one of the ethnic groups.\n",
      "\n",
      "Example 4:\n",
      "Data:\n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Atlanta | isPartOf | DeKalb_County,_Georgia\n",
      "    Atlanta | country | United_States\n",
      "    United_States | ethnicGroup | Native_Americans_in_the_United_States\n",
      "  </snt>\n",
      "</paragraph>\n",
      "Output:\n",
      "Aaron S. Daggett fought at the Battle of Gettysburg, part of the American Civil War. He was given the Purple Heart. A commander in that war was Robert E. Lee.\n",
      "\n",
      "Example 5:\n",
      "Data:\n",
      "<paragraph>\n",
      "  <snt>\n",
      "    Aaron_S._Daggett | battle | Battle_of_Gettysburg\n",
      "    Battle_of_Gettysburg | isPartOfMilitaryConflict | American_Civil_War\n",
      "  </snt>\n",
      "  <snt>\n",
      "    Aaron_S._Daggett | award | Purple_Heart\n",
      "  </snt>\n",
      "  <snt>\n",
      "    American_Civil_War | commander | Robert_E._Lee\n",
      "  </snt>\n",
      "</paragraph>\n",
      "Output:\n",
      "The dark asteroid 1000 Piazzia has an epoch date of 27 June 2015 and a mass of 1.1 kg. Its orbital period is 488160.0, the periapsis is 352497000000.0 and it has the escape velocity of 0.0252 km per sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# def extract_phase_examples(json_path, dataset, phase, max_examples=5):\n",
    "#     with open(json_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     # Filter only examples matching the dataset name\n",
    "#     filtered = [ex for ex in data if ex.get(\"dataset\") == dataset]\n",
    "\n",
    "#     count = 0\n",
    "#     for i, ex in enumerate(filtered[:max_examples], 1):\n",
    "#         # Content Ordering\n",
    "#         if phase == \"content ordering\" and \"ordering\" in ex:\n",
    "#             print(f\"Example {i}:\\nData:\\n{ex['input']}\\nOutput:\\n{ex['ordering']}\\n\")\n",
    "#             count += 1\n",
    "#         # Text Structuring\n",
    "#         elif phase == \"text structuring\" and \"ordering\" in ex and \"structuring\" in ex:\n",
    "#             print(f\"Example {i}:\\nData:\\n{ex['ordering']}\\nOutput:\\n{ex['structuring']}\\n\")\n",
    "#             count += 1\n",
    "#         # Surface Realization\n",
    "#         elif phase == \"surface realization\" and \"structuring\" in ex:\n",
    "#             # Prefer 'target', else 'references'\n",
    "#             output = ex.get('target', None)\n",
    "#             if not output and ex.get(\"references\"):\n",
    "#                 output = ex[\"references\"]\n",
    "#             print(f\"Example {i}:\\nData:\\n{ex['structuring']}\\nOutput:\\n{output}\\n\")\n",
    "#             count += 1\n",
    "\n",
    "#     # print(f\"Total {phase} examples printed: {count}\")\n",
    "\n",
    "# # Usage example:\n",
    "# extract_phase_examples('random_train_samples.json', 'webnlg', 'surface realization', max_examples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
