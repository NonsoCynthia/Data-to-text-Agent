{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9acd5349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: webnlg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from agents.dataloader import load_dataset_by_name\n",
    "\n",
    "# Load dataset\n",
    "name = \"webnlg\"\n",
    "data = load_dataset_by_name(name)\n",
    "dataset = list(data[\"test\"])\n",
    "\n",
    "structgpt = \"results/factual_struct_gpt_base.txt\"\n",
    "struct = \"results/factual_struct_gpt_base.json\"\n",
    "e2e = \"results/webnlg_e2e.json\"\n",
    "agent = \"results/webnlg_agent.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bedeef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices_by_category_and_triple_size(dataset, total_samples=105, seed=42):\n",
    "    # Exclude triple size 1\n",
    "    filtered = [x for x in dataset if len(x.get(\"triples\", x.get(\"input\", []))) > 1]\n",
    "    # Count by (category, triple size)\n",
    "    strat_counts = Counter((x['category'], len(x.get(\"triples\", x.get(\"input\", [])))) for x in filtered)\n",
    "    by_strat = defaultdict(list)\n",
    "    for x in filtered:\n",
    "        strat = (x['category'], len(x.get(\"triples\", x.get(\"input\", []))))\n",
    "        by_strat[strat].append(x)\n",
    "    # Proportional allocation\n",
    "    total = len(filtered)\n",
    "    strat_samples = {strat: max(1, int(total_samples * count / total)) for strat, count in strat_counts.items()}\n",
    "    random.seed(seed)\n",
    "    sampled = []\n",
    "    for strat, items in by_strat.items():\n",
    "        n = strat_samples[strat]\n",
    "        random.shuffle(items)\n",
    "        sampled.extend(items[:n])\n",
    "    # Deduplicate and fill up to total_samples\n",
    "    seen = set()\n",
    "    unique_sampled = []\n",
    "    for x in sampled:\n",
    "        if x[\"id\"] not in seen:\n",
    "            unique_sampled.append(x)\n",
    "            seen.add(x[\"id\"])\n",
    "    sampled = unique_sampled\n",
    "    remaining = [x for x in filtered if x[\"id\"] not in seen]\n",
    "    needed = total_samples - len(sampled)\n",
    "    if needed > 0 and len(remaining) >= needed:\n",
    "        sampled.extend(random.sample(remaining, needed))\n",
    "    elif needed > 0:\n",
    "        sampled.extend(remaining)\n",
    "    if len(sampled) > total_samples:\n",
    "        sampled = random.sample(sampled, total_samples)\n",
    "    return [item[\"id\"] for item in sampled]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "458b7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_indices_by_category(dataset, total_samples=105, seed=42):\n",
    "#     # Exclude triple size 1\n",
    "#     filtered = [x for x in dataset if len(x.get(\"triples\", x.get(\"input\", []))) > 1]\n",
    "#     category_counts = Counter(x['category'] for x in filtered)\n",
    "#     # Floor division for initial allocation\n",
    "#     category_samples = {\n",
    "#         cat: max(1, int(total_samples * count / len(filtered)))\n",
    "#         for cat, count in category_counts.items()\n",
    "#     }\n",
    "#     by_category = defaultdict(list)\n",
    "#     for x in filtered:\n",
    "#         by_category[x['category']].append(x)\n",
    "#     random.seed(seed)\n",
    "#     sampled = []\n",
    "#     # Category-based sampling\n",
    "#     for cat, items in by_category.items():\n",
    "#         n = category_samples[cat]\n",
    "#         random.shuffle(items)\n",
    "#         sampled.extend(items[:n])\n",
    "#     # Remove duplicates if any (just in case)\n",
    "#     seen = set()\n",
    "#     unique_sampled = []\n",
    "#     for x in sampled:\n",
    "#         if x[\"id\"] not in seen:\n",
    "#             unique_sampled.append(x)\n",
    "#             seen.add(x[\"id\"])\n",
    "#     sampled = unique_sampled\n",
    "#     # Fill up to total_samples\n",
    "#     remaining = [x for x in filtered if x[\"id\"] not in seen]\n",
    "#     needed = total_samples - len(sampled)\n",
    "#     if needed > 0:\n",
    "#         sampled.extend(random.sample(remaining, needed))\n",
    "#     # If oversampled, randomly drop extras\n",
    "#     if len(sampled) > total_samples:\n",
    "#         sampled = random.sample(sampled, total_samples)\n",
    "#     return [item[\"id\"] for item in sampled]\n",
    "\n",
    "\n",
    "def load_json_preds(file_path):\n",
    "    preds = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            preds[entry[\"index\"]] = entry[\"prediction\"]\n",
    "    return preds\n",
    "\n",
    "def build_rows(indices, dataset, e2e_preds, agent_preds, struct_lines, columns):\n",
    "    rows = []\n",
    "    for idx in indices:\n",
    "        item = next(x for x in dataset if x[\"id\"] == idx)\n",
    "        triples = \"\\n\".join(item.get(\"triples\", item.get(\"input\", [])))\n",
    "        # Reference\n",
    "        ref = random.choice(item.get(\"references\", []))\n",
    "        rows.append({\n",
    "            \"Index\": item[\"id\"],\n",
    "            \"Model\": \"reference\",\n",
    "            \"Triples\": triples,\n",
    "            \"Output\": ref,\n",
    "            \"Fluency\": \"\",\n",
    "            \"Grammaticality\": \"\",\n",
    "            \"Addition\": \"\",\n",
    "            \"Omission\": \"\"\n",
    "        })\n",
    "        # E2E\n",
    "        if item[\"id\"] in e2e_preds:\n",
    "            rows.append({\n",
    "                \"Index\": item[\"id\"],\n",
    "                \"Model\": \"E2E\",\n",
    "                \"Triples\": triples,\n",
    "                \"Output\": e2e_preds[item[\"id\"]],\n",
    "                \"Fluency\": \"\",\n",
    "                \"Grammaticality\": \"\",\n",
    "                \"Addition\": \"\",\n",
    "                \"Omission\": \"\"\n",
    "            })\n",
    "        # AGENT\n",
    "        if item[\"id\"] in agent_preds:\n",
    "            rows.append({\n",
    "                \"Index\": item[\"id\"],\n",
    "                \"Model\": \"AGENT\",\n",
    "                \"Triples\": triples,\n",
    "                \"Output\": agent_preds[item[\"id\"]],\n",
    "                \"Fluency\": \"\",\n",
    "                \"Grammaticality\": \"\",\n",
    "                \"Addition\": \"\",\n",
    "                \"Omission\": \"\"\n",
    "            })\n",
    "        # StructGPT4\n",
    "        if item[\"id\"] < len(struct_lines):\n",
    "            rows.append({\n",
    "                \"Index\": item[\"id\"],\n",
    "                \"Model\": \"StructGPT4\",\n",
    "                \"Triples\": triples,\n",
    "                \"Output\": struct_lines[item[\"id\"]],\n",
    "                \"Fluency\": \"\",\n",
    "                \"Grammaticality\": \"\",\n",
    "                \"Addition\": \"\",\n",
    "                \"Omission\": \"\"\n",
    "            })\n",
    "    return pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2da47746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created: webnlg_human_eval_study.xlsx\n",
      "Total examples in test set: 1779\n",
      "Total after removing triple size 1: 1410\n",
      "Total sampled indices: 105\n",
      "Pilot indices: 5\n",
      "Human evaluation indices: 100\n"
     ]
    }
   ],
   "source": [
    "# Sample indices\n",
    "all_sampled_indices = sample_indices_by_category(dataset, total_samples=105, seed=42)\n",
    "pilot_indices = all_sampled_indices[:5]\n",
    "human_eval_indices = all_sampled_indices[5:105]\n",
    "\n",
    "# Load predictions\n",
    "e2e_preds = load_json_preds(e2e)\n",
    "agent_preds = load_json_preds(agent)\n",
    "with open(structgpt, \"r\", encoding=\"utf-8\") as f:\n",
    "    struct_lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define columns\n",
    "columns = [\"Index\", \"Model\", \"Triples\", \"Output\", \"Fluency\", \"Grammaticality\", \"Addition\", \"Omission\"]\n",
    "\n",
    "# Build DataFrames\n",
    "df_pilot = build_rows(pilot_indices, dataset, e2e_preds, agent_preds, struct_lines, columns)\n",
    "df_eval = build_rows(human_eval_indices, dataset, e2e_preds, agent_preds, struct_lines, columns)\n",
    "guidelines_columns = [\"Criteria\", \"Definition\", \"Evaluation Points\", \"Scoring Scales\", \"Examples Triples\", \"Example Output\", \"Score\", \"Notes\"]\n",
    "df_blank = pd.DataFrame(columns=guidelines_columns)\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"webnlg_human_eval_study.xlsx\") as writer:\n",
    "    df_blank.to_excel(writer, sheet_name=\"Evaluation Guidelines\", index=False)\n",
    "    df_pilot.to_excel(writer, sheet_name=\"Pilot Study\", index=False)\n",
    "    df_eval.to_excel(writer, sheet_name=\"Human Evaluation\", index=False)\n",
    "    \n",
    "    \n",
    "print(\"Excel file created: webnlg_human_eval_study.xlsx\")\n",
    "print(f\"Total examples in test set: {len(dataset)}\")\n",
    "filtered = [x for x in dataset if len(x.get(\"triples\", x.get(\"input\", []))) > 1]\n",
    "print(f\"Total after removing triple size 1: {len(filtered)}\")\n",
    "print(f\"Total sampled indices: {len(all_sampled_indices)}\")\n",
    "print(f\"Pilot indices: {len(pilot_indices)}\")\n",
    "print(f\"Human evaluation indices: {len(human_eval_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: webnlg\n",
      "Done! Saved to results/factual_struct_gpt_base.json\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# from agents.dataloader import load_dataset_by_name\n",
    "\n",
    "# # Load WebNLG test set\n",
    "# name = \"webnlg\"\n",
    "# data = load_dataset_by_name(name)\n",
    "# dataset = list(data[\"test\"])\n",
    "\n",
    "# Load predictions\n",
    "with open(structgpt, \"r\", encoding=\"utf-8\") as f:\n",
    "    predictions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Build json objects\n",
    "results = []\n",
    "for i, item in enumerate(dataset):\n",
    "    output = predictions[i] if i < len(predictions) else \"\"\n",
    "    result = {\n",
    "        \"index\": item[\"id\"],\n",
    "        # \"triples\": item.get(\"triples\", []),\n",
    "        \"prediction\": output\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"results/factual_struct_gpt_base.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Done! Saved to results/factual_struct_gpt_base.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5863346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts saved to results/webnlg_e2e\n",
      "Texts saved to results/webnlg_agent\n",
      "Texts saved to results/factual_struct_gpt_base\n"
     ]
    }
   ],
   "source": [
    "e2e_preds = load_json_preds(e2e)\n",
    "agent_preds = load_json_preds(agent)\n",
    "struct_preds = load_json_preds(struct)\n",
    "\n",
    "def load_texts(file_path, text_dict):\n",
    "    \"\"\"\n",
    "    Save each value from a dict as a line in a .txt file.\n",
    "    \"\"\"\n",
    "    txt_path = file_path.replace(\".json\", \"\")\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for text in text_dict.values():\n",
    "            text = text.replace(\"\\n\", \" \").strip()\n",
    "            f.write(str(text) + \"\\n\")\n",
    "    print(f\"Texts saved to {txt_path}\")\n",
    "\n",
    "load_texts(e2e, e2e_preds)\n",
    "load_texts(agent, agent_preds)\n",
    "load_texts(struct, struct_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee99631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'triples': ['Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca',\n",
       "  'Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C',\n",
       "  'Campeonato_Brasileiro_Série_C | country | Brazil',\n",
       "  'Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\"',\n",
       "  'Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca'],\n",
       " 'num_triples': '5',\n",
       " 'category': 'SportsTeam',\n",
       " 'references': ['Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Agremiação Sportiva Arapiraquense, nicknamed \"Alvinegro\", lay in the Campeonato Brasileiro Série C league from Brazil.',\n",
       "  'Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Alvinegro, the nickname of Agremiação Sportiva Arapiraquense, play in the Campeonato Brasileiro Série C league from Brazil.']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6214023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: webnlg_hf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from agents.dataloader import load_dataset_by_name\n",
    "\n",
    "# Load WebNLG test set\n",
    "name = \"webnlg_hf\"\n",
    "data = load_dataset_by_name(name)\n",
    "dataset = list(data[\"test\"])\n",
    "\n",
    "with open(\"results/triples\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in dataset:\n",
    "        triples = item.get(\"triples\", None)\n",
    "        # Prefer the 'triples' field; fallback to 'input'\n",
    "        if not triples:\n",
    "            triples = item.get(\"input\", None)\n",
    "        if triples:\n",
    "            # If triples is a list, join with comma and space\n",
    "            if isinstance(triples, list):\n",
    "                line = \", \".join(str(t).replace(\"\\n\", \" \").strip() for t in triples)\n",
    "            else:  # If already string, just clean it up\n",
    "                line = str(triples).replace(\"\\n\", \" \").strip()\n",
    "            f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15efa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert your dataset to a list if not already done\n",
    "# all_examples = list(dataset)\n",
    "\n",
    "# # 1. Count examples per category\n",
    "# category_counts = Counter(x['category'] for x in all_examples)\n",
    "\n",
    "# # 2. Proportional allocation of 105 samples across categories\n",
    "# total_samples = 105\n",
    "# category_samples = {\n",
    "#     cat: max(1, round(total_samples * count / len(all_examples)))\n",
    "#     for cat, count in category_counts.items()\n",
    "# }\n",
    "\n",
    "# # 3. Group by category\n",
    "# by_category = defaultdict(list)\n",
    "# for x in all_examples:\n",
    "#     by_category[x['category']].append(x)\n",
    "\n",
    "# # 4. Randomly sample from each category\n",
    "# random.seed(42)\n",
    "# sampled = []\n",
    "# for cat, items in by_category.items():\n",
    "#     n = category_samples[cat]\n",
    "#     random.shuffle(items)\n",
    "#     sampled.extend(items[:n])\n",
    "\n",
    "# # 5. If oversampled, randomly drop extra to get exactly 105\n",
    "# if len(sampled) > total_samples:\n",
    "#     sampled = random.sample(sampled, total_samples)\n",
    "\n",
    "# # 6. Get the indices (IDs) for these 105 samples\n",
    "# all_sampled_indices = [item[\"id\"] for item in sampled]\n",
    "\n",
    "# # 7. Divide into pilot (first 5) and human evaluation (next 100)\n",
    "# pilot_indices = all_sampled_indices[:5]\n",
    "# human_eval_indices = all_sampled_indices[5:105]\n",
    "\n",
    "# columns = [\"Index\", \"Model\", \"Triples\", \"Output\", \"Fluency\", \"Grammaticality\", \"Addition\", \"Omission\"]\n",
    "# print(f\"pilot_indices: {pilot_indices}\")\n",
    "# print(f\"human_eval_indices: {human_eval_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70367d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Load E2E and Agent predictions ---\n",
    "# def load_jsonl(file_path):\n",
    "#     preds = {}\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             entry = json.loads(line)\n",
    "#             preds[entry[\"index\"]] = entry[\"prediction\"]\n",
    "#     return preds\n",
    "\n",
    "# e2e_preds = load_jsonl(\"results/webnlg_e2e.json\") \n",
    "# agent_preds = load_jsonl(\"results/webnlg_agent.json\")\n",
    "\n",
    "# # --- Load StructGPT4 predictions ---\n",
    "# with open(\"results/factual_struct_gpt_base.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     struct_lines = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pilot_rows = []\n",
    "# for idx in pilot_indices:\n",
    "#     item = dataset[idx]\n",
    "#     triples = \"\\n\".join(item.get(\"triples\", item.get(\"input\", [])))\n",
    "#     # Reference row\n",
    "#     ref = random.choice(item.get(\"references\", []))\n",
    "#     pilot_rows.append({\n",
    "#         \"Index\": item[\"id\"],\n",
    "#         \"Model\": \"reference\",\n",
    "#         \"Triples\": triples,\n",
    "#         \"Output\": ref,\n",
    "#         \"Fluency\": \"\",\n",
    "#         \"Grammaticality\": \"\",\n",
    "#         \"Addition\": \"\",\n",
    "#         \"Omission\": \"\"\n",
    "#     })\n",
    "#     # E2E row\n",
    "#     if item[\"id\"] in e2e_preds:\n",
    "#         pilot_rows.append({\n",
    "#             \"Index\": item[\"id\"],\n",
    "#             \"Model\": \"E2E\",\n",
    "#             \"Triples\": triples,\n",
    "#             \"Output\": e2e_preds[item[\"id\"]],\n",
    "#             \"Fluency\": \"\",\n",
    "#             \"Grammaticality\": \"\",\n",
    "#             \"Addition\": \"\",\n",
    "#             \"Omission\": \"\"\n",
    "#         })\n",
    "#         # AGENT row\n",
    "#     if item[\"id\"] in e2e_preds:\n",
    "#         pilot_rows.append({\n",
    "#             \"Index\": item[\"id\"],\n",
    "#             \"Model\": \"E2E\",\n",
    "#             \"Triples\": triples,\n",
    "#             \"Output\": agent_preds[item[\"id\"]],\n",
    "#             \"Fluency\": \"\",\n",
    "#             \"Grammaticality\": \"\",\n",
    "#             \"Addition\": \"\",\n",
    "#             \"Omission\": \"\"\n",
    "#         })\n",
    "#     # StructGPT4 row (check if line exists)\n",
    "#     if item[\"id\"] < len(struct_lines):\n",
    "#         pilot_rows.append({\n",
    "#             \"Index\": item[\"id\"],\n",
    "#             \"Model\": \"StructGPT4\",\n",
    "#             \"Triples\": triples,\n",
    "#             \"Output\": struct_lines[item[\"id\"]],\n",
    "#             \"Fluency\": \"\",\n",
    "#             \"Grammaticality\": \"\",\n",
    "#             \"Addition\": \"\",\n",
    "#             \"Omission\": \"\"\n",
    "#         })\n",
    "\n",
    "# df_pilot = pd.DataFrame(pilot_rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d18294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save or append as a sheet in your Excel\n",
    "# eval_rows = []\n",
    "# for idx in human_eval_indices:\n",
    "#     item = dataset[idx]\n",
    "#     triples = \"\\n\".join(item.get(\"triples\", item.get(\"input\", [])))\n",
    "#     # 1. Reference\n",
    "#     reference_text = random.choice(item.get(\"references\", []))\n",
    "#     eval_rows.append({\n",
    "#         \"Index\": item[\"id\"],\n",
    "#         \"Model\": \"reference\",\n",
    "#         \"Triples\": triples,\n",
    "#         \"Output\": reference_text,\n",
    "#         \"Fluency\": \"\",\n",
    "#         \"Grammaticality\": \"\",\n",
    "#         \"Addition\": \"\",\n",
    "#         \"Omission\": \"\"\n",
    "#     })\n",
    "#     # 2. E2E\n",
    "#     if item[\"id\"] in e2e_preds:\n",
    "#         eval_rows.append({\n",
    "#             \"Index\": item[\"id\"],\n",
    "#             \"Model\": \"E2E\",\n",
    "#             \"Triples\": triples,\n",
    "#             \"Output\": e2e_preds[item[\"id\"]],\n",
    "#             \"Fluency\": \"\",\n",
    "#             \"Grammaticality\": \"\",\n",
    "#             \"Addition\": \"\",\n",
    "#             \"Omission\": \"\"\n",
    "#         })\n",
    "#     # 3. StructGPT4\n",
    "#     if item[\"id\"] < len(struct_lines):\n",
    "#         eval_rows.append({\n",
    "#             \"Index\": item[\"id\"],\n",
    "#             \"Model\": \"StructGPT4\",\n",
    "#             \"Triples\": triples,\n",
    "#             \"Output\": struct_lines[item[\"id\"]],\n",
    "#             \"Fluency\": \"\",\n",
    "#             \"Grammaticality\": \"\",\n",
    "#             \"Addition\": \"\",\n",
    "#             \"Omission\": \"\"\n",
    "#         })\n",
    "#     # 4. AGENT (reference blank)\n",
    "#     eval_rows.append({\n",
    "#         \"Index\": item[\"id\"],\n",
    "#         \"Model\": \"AGENT\",\n",
    "#         \"Triples\": triples,\n",
    "#         \"Output\": agent_preds[item[\"id\"]],\n",
    "#         \"Fluency\": \"\",\n",
    "#         \"Grammaticality\": \"\",\n",
    "#         \"Addition\": \"\",\n",
    "#         \"Omission\": \"\"\n",
    "#     })\n",
    "\n",
    "# df_eval = pd.DataFrame(eval_rows, columns=columns)\n",
    "\n",
    "# guidlines_columns = [\"Criteria\", \"Definition\", \"Evaluation Points\", \"Scoring Scales\", \"Examples Triples\", \"Example Output\", \"Score\", \"Notes\"]\n",
    "# df_blank = pd.DataFrame(columns=guidlines_columns)\n",
    "\n",
    "# # # Save or append as a sheet in your Excel\n",
    "# # with pd.ExcelWriter(\"webnlg_human_eval_study.xlsx\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "# #     df_eval.to_excel(writer, sheet_name=\"Human Evaluation\", index=False)\n",
    "\n",
    "# # print(\"Human Evaluation sheet populated with all models and references (AGENT left blank for reference).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6239e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(\"webnlg_human_eval_study.xlsx\") as writer:\n",
    "#     df_blank.to_excel(writer, sheet_name=\"Evluation Guidelines\", index=False)\n",
    "#     df_pilot.to_excel(writer, sheet_name=\"Pilot Study\", index=False)\n",
    "#     df_eval.to_excel(writer, sheet_name=\"Human Evaluation\", index=False)\n",
    "# print(\"Excel file created: webnlg_human_eval_study.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e8adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209afd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59acb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
